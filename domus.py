# -*- coding: utf-8 -*-
"""Copy of domus.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1--egw7f-PlyAgKFUcP2Os0GICSRZa2lj
"""

# !pip install requests
# !pip install beautifulsoup4
# !pip install pandas
# !pip install sentence-transformers
# !pip install pinecone

"""#IMPORTS
####Pinecone - Vector DB
####Sentence transformers - Vector Embeddings
####bs4 - scraper

"""

import os
import requests
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
from bs4 import BeautifulSoup
import re

class KenyanRealEstateVectorSearch:
    def __init__(self, pinecone_api_key, embedding_model='all-MiniLM-L6-v2'):
        """
        Initialize the vector search system

        Args:
            pinecone_api_key (str): API key for Pinecone vector database
            embedding_model (str): Sentence transformer model for embeddings
        """
        self.pc = Pinecone(api_key=pinecone_api_key)
        self.model = SentenceTransformer(embedding_model)

        # Create Pinecone index if not exists
        index_name = 'domus-estate'
        if index_name not in self.pc.list_indexes().names():
            self.pc.create_index(
                name=index_name,
                dimension=self.model.get_sentence_embedding_dimension(),
                metric='cosine'
            )
        self.index = self.pc.Index(index_name)

    def scrape_property24(self, url):
        """
        Scrape property details from Property24 Kenya

        Args:
            url (str): Property24 search results URL

        Returns:
            pd.DataFrame: Scraped property listings
        """
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')

        properties = []

        # Extract property cards (adjust selectors as needed)
        for prop_card in soup.find_all('div', class_='property-card'):
            property_details = {
                'title': prop_card.find('h2', class_='title').text.strip(),
                'price': prop_card.find('span', class_='price').text.strip(),
                'location': prop_card.find('div', class_='location').text.strip(),
                'bedrooms': prop_card.find('span', class_='bedrooms').text.strip(),
                'bathrooms': prop_card.find('span', class_='bathrooms').text.strip(),
                'description': prop_card.find('p', class_='description').text.strip(),
                'url': prop_card.find('a', class_='property-link')['href']
            }
            properties.append(property_details)

        return pd.DataFrame(properties)

    def create_embeddings(self, dataframe):
        """
        Create vector embeddings for property listings

        Args:
            dataframe (pd.DataFrame): Property listings

        Returns:
            np.array: Vector embeddings
        """
        # Combine text features for embedding
        text_features = dataframe.apply(
            lambda row: f"{row['title']} {row['location']} {row['description']}",
            axis=1
        )

        return self.model.encode(text_features.tolist())

    def index_properties(self, dataframe, embeddings):
        """
        Index property listings in Pinecone

        Args:
            dataframe (pd.DataFrame): Property listings
            embeddings (np.array): Vector embeddings
        """
        # Prepare vectors for indexing
        vectors = [
            {
                'id': str(idx),
                'values': embedding.tolist(),
                'metadata': row.to_dict()
            }
            for idx, (embedding, row) in enumerate(zip(embeddings, dataframe.to_dict('records')))
        ]

        # Upsert to Pinecone
        self.index.upsert(vectors)

    def search_properties(self, query, top_k=5):
        """
        Perform semantic search on property listings

        Args:
            query (str): Search query
            top_k (int): Number of results to return

        Returns:
            list: Top matching property listings
        """
        # Convert query to embedding
        query_embedding = self.model.encode([query])[0]

        # Search Pinecone index
        results = self.index.query(
            vector=query_embedding.tolist(),
            top_k=top_k,
            include_metadata=True
        )

        return [result['metadata'] for result in results['matches']]

# Example usage
def main():
    # Replace with your actual Pinecone API key
    PINECONE_API_KEY = 'pcsk_7NDWRP_PaeWqeaXZ2YXPG7a92DyqCpDQszqFUdgS7hJfiRnEKAvxoU3PVYrji3ucjB65dv'

    # Initialize vector search system
    vector_search = KenyanRealEstateVectorSearch(PINECONE_API_KEY)

    # Scrape Property24 (use actual URL)
    property_url = 'https://www.property24.co.ke/search-results'
    properties_df = vector_search.scrape_property24(property_url)

    # Create embeddings
    embeddings = vector_search.create_embeddings(properties_df)

    # Index properties
    vector_search.index_properties(properties_df, embeddings)

    # Example search
    search_results = vector_search.search_properties("3 bedroom apartment near Nairobi CBD")
    print(search_results)

if __name__ == '__main__':
    main()